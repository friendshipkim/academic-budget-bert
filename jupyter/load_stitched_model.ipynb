{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "# from ../pretraining/base.py import BasePretrainModel\n",
    "from pretraining.base import BasePretrainModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "model_config={'vocab_size': 30522, 'hidden_size': 1024, 'num_hidden_layers': 24, 'num_attention_heads': 8, 'intermediate_size': 4096, 'hidden_act': 'gelu', 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 512, 'layernorm_embedding': False, 'type_vocab_size': 2, 'initializer_range': 0.02, 'fused_linear_layer': True, 'sparse_mask_prediction': True, 'encoder_ln_mode': 'pre-ln', 'layer_norm_type': 'apex'}\n",
    "args = Namespace(deepspeed=True, deepspeed_transformer_kernel=False, stochastic_mode=False, attention_dropout_checkpoint=False, normalize_invertible=False, gelu_checkpoint=False, gradient_clipping=0.0, steps_per_print=100, wall_clock_breakdown=False, prescale_gradients=False, gradient_predivide_factor=None, fp16=True, fp16_backend='ds', fp16_opt='O2', model_type='bert-mlm', model_name_or_path=None, config_name=None, tokenizer_name='bert-large-uncased', load_tokenizer_locally=False, cache_dir=None, pretrain_run_args=None, dataset_path='/opt/ml/data/total/', num_workers=4, async_worker=True, data_loader_type='dist', seed=42, output_dir='/opt/ml/data/saved_models/4stitch', max_predictions_per_seq=20, local_rank=0, load_training_checkpoint=None, load_checkpoint_id=None, num_epochs_between_checkpoints=10, job_name='4xhalflarge-total', project_name='budget-bert-pretraining', max_steps=500, max_steps_per_epoch=9223372036854775807, print_steps=100, do_validation=True, validation_epochs=3, validation_epochs_begin=1, validation_epochs_end=1, validation_begin_proportion=0.05, validation_end_proportion=0.01, validation_micro_batch=16, validation_shards=1, add_nsp=False, current_run_id='total', early_exit_time_marker=100.0, total_training_time=100.0, finetune_time_markers=None, finetune_checkpoint_at_end=True, gradient_accumulation_steps=1, train_batch_size=4096, train_micro_batch_size_per_gpu=256, num_epochs=1000000, lr=0.001, use_early_stopping=False, early_stop_time=720, early_stop_eval_loss=2.1, scale_cnt_limit=100, log_throughput_every=20, no_nsp=True, learning_rate=0.001, do_stitch=True, src_model1_path='/opt/ml/data/saved_models/halflarge_213-set1-10ksteps/set1-10ksteps/epoch1000000_step10023/', src_model2_path='/opt/ml/data/saved_models/halflarge_146-set1-10ksteps/set1-10ksteps/epoch1000000_step10031/', src_model3_path='/opt/ml/data/saved_models/halflarge_95-set1-10ksteps/set1-10ksteps/epoch1000000_step10005/', src_model4_path='/opt/ml/data/saved_models/halflarge_199-set1-10ksteps/set1-10ksteps/epoch1000000_step10014/', skip_layernorm=False, saved_model_path='/opt/ml/data/saved_models/4stitch/4xhalflarge-total/total', exp_start_marker=21446606.92100428, vocab_size=30528, model_config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/20/2023 00:36:04 - INFO - pretraining.base -   Loading default tokenizer bert-large-uncased\n",
      "02/20/2023 00:36:07 - INFO - pretraining.base -   Loading config from args\n",
      "02/20/2023 00:36:07 - INFO - pretraining.base -   VOCAB SIZE: 30528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "{}\n",
      "()\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/20/2023 00:36:07 - INFO - pretraining.modeling -   Init BERT pretrain model\n"
     ]
    }
   ],
   "source": [
    "model = BasePretrainModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/opt/ml/data/saved_models/4stitch/4xhalflarge-total/total/epoch1000000_step507/\"\n",
    "checkpoint3 = torch.load(path + \"pytorch_model.bin\")\n",
    "model.network.load_state_dict(checkpoint3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
