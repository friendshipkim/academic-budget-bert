{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/miniconda3/envs/pretrain/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9becfdd0b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch set seed\n",
    "torch.manual_seed(33)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 32\n",
    "d0_in = 1000\n",
    "d0_out = 512\n",
    "d0_out_new = 768\n",
    "\n",
    "d1_in = d0_out\n",
    "d1_in_new = d0_out_new\n",
    "d1_out = 2048\n",
    "d1_out_new = 3072\n",
    "\n",
    "d2_in = d1_out\n",
    "d2_in_new = d1_out_new\n",
    "d2_out = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_0 - src: 2x[512, 1000] -> tgt: [768, 2x1000]\n",
      "W_1 - src: 2x[2048, 512] -> tgt: [3072, 768]\n",
      "W_2 - src: 3x[1000, 2048] -> tgt: [2x1000, 3072]\n"
     ]
    }
   ],
   "source": [
    "# target weight shape\n",
    "print(f\"W_0 - src: 2x[{d0_out}, {d0_in}] -> tgt: [{d0_out_new}, 2x{d0_in}]\")\n",
    "print(f\"W_1 - src: 2x[{d1_out}, {d1_in}] -> tgt: [{d1_out_new}, {d1_in_new}]\")\n",
    "print(f\"W_2 - src: 3x[{d2_out}, {d2_in}] -> tgt: [2x{d2_out}, {d2_in_new}]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "x1 = torch.rand(n, d0_in) / math.sqrt(d0_in)\n",
    "x2 = torch.rand(n, d0_in) / math.sqrt(d0_in)\n",
    "\n",
    "x = torch.concat((x1, x2), dim=-1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1000]) torch.Size([512, 1000])\n",
      "torch.Size([1024, 2000])\n"
     ]
    }
   ],
   "source": [
    "# 0th layer weights\n",
    "A0 = torch.rand(d0_out, d0_in) / math.sqrt(d0_out)\n",
    "B0 = torch.rand(d0_out, d0_in) / math.sqrt(d0_out)\n",
    "zeros = torch.zeros(d0_out, d0_in)\n",
    "W0_diag = torch.concat((torch.concat((A0, zeros), dim=0), torch.concat((zeros, B0), dim=0)), dim=-1)\n",
    "\n",
    "print(A0.shape, B0.shape)\n",
    "print(W0_diag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 512]) torch.Size([2048, 512])\n",
      "torch.Size([4096, 1024])\n"
     ]
    }
   ],
   "source": [
    "# 1th layer weights\n",
    "A1 = torch.rand(d1_out, d1_in) / math.sqrt(d1_out)\n",
    "B1 = torch.rand(d1_out, d1_in) / math.sqrt(d1_out)\n",
    "zeros = torch.zeros(d1_out, d1_in)\n",
    "W1_diag = torch.concat((torch.concat((A1, zeros), dim=0), torch.concat((zeros, B1), dim=0)), dim=-1)\n",
    "\n",
    "print(A1.shape, B1.shape)\n",
    "print(W1_diag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2048]) torch.Size([1000, 2048])\n",
      "torch.Size([2000, 4096])\n"
     ]
    }
   ],
   "source": [
    "# 2th layer weights\n",
    "A2 = torch.rand(d2_out, d2_in) / math.sqrt(d2_out)\n",
    "B2 = torch.rand(d2_out, d2_in) / math.sqrt(d2_out)\n",
    "zeros = torch.zeros(d2_out, d2_in)\n",
    "W2_diag = torch.concat((torch.concat((A2, zeros), dim=0), torch.concat((zeros, B2), dim=0)), dim=-1)\n",
    "\n",
    "print(A2.shape, B2.shape)\n",
    "print(W2_diag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_weights = [W0_diag, W1_diag, W2_diag]\n",
    "separate_weights = [A0, B0, A1, B1, A2, B2]\n",
    "inputs = [x1, x2, x]\n",
    "\n",
    "for m in diag_weights + separate_weights + inputs:\n",
    "    m.to(\"cuda:2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_covariance(W, n_components):\n",
    "    # PCA on covariance matrix\n",
    "    U, S, V = torch.pca_lowrank(W @ W.T, q=n_components, center=False)\n",
    "        \n",
    "    # expansion/reduction matrix\n",
    "    E = torch.sqrt(torch.diag(S)) @ U.T\n",
    "    E_inv = U @ torch.linalg.pinv(torch.sqrt(torch.diag(S)))  # TODO: check if V -> U makes sense\n",
    "\n",
    "    # output weight\n",
    "    W_out_expand = E @ W\n",
    "    \n",
    "    return W_out_expand, E_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_weight(W, n_components):\n",
    "    # PCA on weight matrix\n",
    "    U, S, V = torch.pca_lowrank(W, q=n_components, center=False)\n",
    "        \n",
    "    # expansion/reduction matrix\n",
    "    E = U.T\n",
    "    E_inv = E.T\n",
    "    \n",
    "    # output weight\n",
    "    W_out_expand = torch.diag(S) @ V.T\n",
    "    \n",
    "    return W_out_expand, E_inv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_out_pca_diag(W_diag, d_out_new):\n",
    "    # dimension check\n",
    "    d_out_double, d_in_double = W_diag.shape\n",
    "    assert d_out_double >= d_out_new > (d_out_double / 2)\n",
    "    \n",
    "    if min(d_out_double, d_in_double) <= d_out_new:\n",
    "        print(f\"PCA on covariance matrix, since min({d_out_double}, {d_in_double}) <= {d_out_new}\")\n",
    "        W_out_expand, E_inv = pca_covariance(W_diag, n_components=d_out_new)\n",
    "    else:\n",
    "        # NOTE: this can be done with covariance matrix as well\n",
    "        print(f\"PCA on weight matrix\")\n",
    "        W_out_expand, E_inv = pca_weight(W_diag, n_components=d_out_new)\n",
    "        \n",
    "    print(f\"Mean reconstruction error: {torch.abs(E_inv @ W_out_expand - W_diag).mean()}\")\n",
    "    \n",
    "    # output dimension sanity check\n",
    "    assert W_out_expand.shape == (d_out_new, d_in_double)\n",
    "    assert E_inv.shape == (d_out_double, d_out_new)\n",
    "    \n",
    "    return W_out_expand, E_inv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA on weight matrix\n",
      "Mean reconstruction error: 0.0017343397485092282\n",
      "torch.Size([768, 2000]) torch.Size([1024, 768])\n"
     ]
    }
   ],
   "source": [
    "# PCA on W0_diag\n",
    "W0_out_expand, E0_inv = expand_out_pca_diag(W0_diag, d0_out_new)\n",
    "print(W0_out_expand.shape, E0_inv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA on covariance matrix, since min(4096, 1024) <= 3072\n",
      "Mean reconstruction error: 8.01863251354007e-08\n",
      "torch.Size([3072, 1024]) torch.Size([4096, 3072])\n"
     ]
    }
   ],
   "source": [
    "# PCA on W1_diag\n",
    "W1_out_expand, E1_inv = expand_out_pca_diag(W1_diag, d1_out_new)\n",
    "print(W1_out_expand.shape, E1_inv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new weights\n",
    "W0_new = W0_out_expand\n",
    "W1_new = W1_out_expand @ E0_inv\n",
    "W2_new = W2_diag @ E1_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare outputs\n",
    "out = x @ W0_diag.T @ W1_diag.T @ W2_diag.T\n",
    "out_new = x @ W0_new.T @ W1_new.T @ W2_new.T\n",
    "torch.abs(out - out_new).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2,3,4]).data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_out_pca_separately(A, B, d_out_new):\n",
    "    # dimension check\n",
    "    d_out, d_in = A.shape\n",
    "    assert A.shape == B.shape\n",
    "    assert d_out * 2 >= d_out_new > d_out\n",
    "    \n",
    "    d_out_new_half = d_out_new // 2\n",
    "    \n",
    "    W_out_expands = []\n",
    "    E_invs = []\n",
    "    for W in (A, B):\n",
    "        if min(d_out, d_in) <= d_out_new_half:\n",
    "            print(f\"PCA on covariance matrix, since min({d_out}, {d_in}) <= {d_out_new_half}\")\n",
    "            W_out_expand, E_inv = pca_covariance(W, n_components=d_out_new_half)\n",
    "        else:\n",
    "            print(f\"PCA on weight matrix\")\n",
    "            # NOTE: this can be done with covariance matrix as well\n",
    "            W_out_expand, E_inv = pca_weight(W, n_components=d_out_new_half)\n",
    "            \n",
    "            print(f\"Mean reconstruction error: {torch.abs(E_inv @ W_out_expand - W).mean()}\")\n",
    "            \n",
    "        print(W_out_expand.shape, E_inv.shape)\n",
    "            \n",
    "        W_out_expands.append(W_out_expand)\n",
    "        E_invs.append(E_inv)\n",
    "        \n",
    "    return W_out_expands, E_invs\n",
    "    \n",
    "    # output dimension sanity check\n",
    "    assert W_out_expand.shape == (d_out_new, d_in_double)\n",
    "    assert E_inv.shape == (d_out_double, d_out_new)\n",
    "    \n",
    "    return W_out_expand, E_inv\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA on weight matrix\n",
      "Mean reconstruction error: 0.0026181077118963003\n",
      "torch.Size([384, 1000]) torch.Size([512, 384])\n",
      "PCA on weight matrix\n",
      "Mean reconstruction error: 0.002612665994092822\n",
      "torch.Size([384, 1000]) torch.Size([512, 384])\n"
     ]
    }
   ],
   "source": [
    "# PCA on A0, B0 separately\n",
    "# diagonal weights -> W0_out_expand: [768, 2000], E0_inv: [1024, 768]\n",
    "# equivelent to concatnating the output\n",
    "W0_out_expands, E0_invs = expand_out_pca_separately(A0, B0, d0_out_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA on covariance matrix, since min(2048, 512) <= 1536\n",
      "torch.Size([1536, 512]) torch.Size([2048, 1536])\n",
      "PCA on covariance matrix, since min(2048, 512) <= 1536\n",
      "torch.Size([1536, 512]) torch.Size([2048, 1536])\n"
     ]
    }
   ],
   "source": [
    "# PCA on A1, B1 separately\n",
    "# diagonal weights -> W1_out_expand: [3072, 1024], E0_inv: [4096, 3072]\n",
    "W1_out_expands, E1_invs = expand_out_pca_separately(A1, B1, d1_out_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new weights\n",
    "W0_news = W0_out_expands\n",
    "W1_news = [W1_out_expand @ E0_inv for W1_out_expand, E0_inv in zip(W1_out_expands, E0_invs)]\n",
    "W2_news = [W2 @ E1_inv for W2, E1_inv in zip([A2, B2], E1_invs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare outputs\n",
    "out = x @ W0_diag.T @ W1_diag.T @ W2_diag.T\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare outputs\n",
    "out = x @ W0_diag.T @ W1_diag.T @ W2_diag.T\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1000]), torch.Size([32, 1000]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_new_1 = x1 @ W0_news[0].T @ W1_news[0].T @ W2_news[0].T\n",
    "out_new_2 = x2 @ W0_news[1].T @ W1_news[1].T @ W2_news[1].T\n",
    "out_new_1.shape, out_new_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_new = torch.concat([out_new_1, out_new_2], dim=-1)\n",
    "out_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(out - out_new).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 4.64MB/s]\n",
      "Downloading: 100%|██████████| 440M/440M [00:03<00:00, 114MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30522, 384]) torch.Size([30522, 384])\n"
     ]
    }
   ],
   "source": [
    "embedding_a = model.bert.embeddings.word_embeddings.weight.detach()[:, :384]\n",
    "embedding_b = model.bert.embeddings.word_embeddings.weight.detach()[:, -384:]\n",
    "\n",
    "print(embedding_a.shape, embedding_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA on weight matrix\n",
      "Mean reconstruction error: 0.011709071695804596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 30522]), torch.Size([768, 512]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pca on concatenated embeddings\n",
    "emb_out_expand, emb_inv = expand_out_pca_diag(torch.concat((embedding_a, embedding_b), dim=-1).T, 512)\n",
    "emb_out_expand.shape, emb_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA on weight matrix\n",
      "Mean reconstruction error: 0.013286596164107323\n",
      "torch.Size([256, 30522]) torch.Size([384, 256])\n",
      "PCA on weight matrix\n",
      "Mean reconstruction error: 0.01326266210526228\n",
      "torch.Size([256, 30522]) torch.Size([384, 256])\n"
     ]
    }
   ],
   "source": [
    "# pca on separate embeddings\n",
    "emb_out_expands, emb_invs = expand_out_pca_separately(embedding_a.T, embedding_b.T, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
